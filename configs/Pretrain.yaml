train_file: [
  "/net/acadia10a/data/zkhan/coco2017/pretrain-pairs.json",
  "/net/acadia10a/data/zkhan/visual-genome-sandbox/visual-genome-pairs.json",
  "/net/acadia10a/data/zkhan/cc3m/cc3m-train-pairs.json",
  "/net/acadia10a/data/zkhan/cc3m/cc3m-val-pairs.json",
  "/net/acadia10a/data/zkhan/sbu-captions/sbu-pretrain-pairs.json",
               ]
# each train_file (json) contains a python list where each item is {'image': img_path, 'caption': text or list_of_text }               
bert_config: 'configs/shared_bert.json'

image_res: 256
vision_width: 768
embed_dim: 256
batch_size: 64
temp: 0.07
mlm_probability: 0.15
queue_size: 65536
momentum: 0.995
alpha: 0.4
image_tokenizer_path: /net/acadia10a/data/zkhan/dall-e-tokenizer-weights

optimizer: {opt: adamW, lr: 1e-4, weight_decay: 0.02}
schedular: {sched: cosine, lr: 1e-4, epochs: 30, min_lr: 1e-5, decay_rate: 1, warmup_lr: 1e-5, warmup_epochs: 20, cooldown_epochs: 0}







